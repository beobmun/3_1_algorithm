{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 눈깜빡임 감지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 19:09:02.559147: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2586, 26, 34, 1) (2586, 1)\n",
      "(288, 26, 34, 1) (288, 1)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "\n",
    "x_train = np.load('dataset/x_train.npy').astype(np.float32)\n",
    "y_train = np.load('dataset/y_train.npy').astype(np.float32)\n",
    "x_val = np.load('dataset/x_val.npy').astype(np.float32)\n",
    "y_val = np.load('dataset/y_val.npy').astype(np.float32)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "\trescale=1./255,\n",
    " rotation_range=10,\n",
    " width_shift_range=0.2,\n",
    " height_shift_range=0.2,\n",
    " shear_range=0.2\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(x=x_train, y=y_train, batch_size=32, shuffle=True)\n",
    "val_generator = val_datagen.flow(x=x_val, y=y_val, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 34, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 17, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 17, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               786944    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 19:09:09.039045: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-28 19:09:09.039098: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(26, 34, 1))\n",
    "\n",
    "net = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "\n",
    "net = Dense(512)(net)\n",
    "net = Activation('relu')(net)\n",
    "net = Dense(1)(net)\n",
    "outputs = Activation('sigmoid')(net)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q5/qkpj78lx0cq03d5wc8y0v97r0000gn/T/ipykernel_4955/369367441.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n",
      "2023-05-28 19:09:10.333119: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-28 19:09:10.816114: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-28 19:09:10.898368: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.4488 - acc: 0.7800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 19:09:12.617781: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-28 19:09:12.693114: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_acc improved from -inf to 0.90625, saving model to models/2023_05_28_19_09_10.h5\n",
      "81/81 [==============================] - 3s 20ms/step - loss: 0.4476 - acc: 0.7804 - val_loss: 0.2471 - val_acc: 0.9062 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2399 - acc: 0.9119\n",
      "Epoch 2: val_acc improved from 0.90625 to 0.95833, saving model to models/2023_05_28_19_09_10.h5\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.2387 - acc: 0.9126 - val_loss: 0.1203 - val_acc: 0.9583 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1759 - acc: 0.9370\n",
      "Epoch 3: val_acc did not improve from 0.95833\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.1747 - acc: 0.9374 - val_loss: 0.0709 - val_acc: 0.9583 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1541 - acc: 0.9561\n",
      "Epoch 4: val_acc did not improve from 0.95833\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.1529 - acc: 0.9567 - val_loss: 0.1286 - val_acc: 0.9479 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9597\n",
      "Epoch 5: val_acc improved from 0.95833 to 0.96181, saving model to models/2023_05_28_19_09_10.h5\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.1246 - acc: 0.9598 - val_loss: 0.0994 - val_acc: 0.9618 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.1259 - acc: 0.9617\n",
      "Epoch 6: val_acc improved from 0.96181 to 0.98611, saving model to models/2023_05_28_19_09_10.h5\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.1259 - acc: 0.9617 - val_loss: 0.0387 - val_acc: 0.9861 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.9714\n",
      "Epoch 7: val_acc did not improve from 0.98611\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.0880 - acc: 0.9714 - val_loss: 0.0564 - val_acc: 0.9826 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0991 - acc: 0.9691\n",
      "Epoch 8: val_acc did not improve from 0.98611\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0991 - acc: 0.9691 - val_loss: 0.0451 - val_acc: 0.9861 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0765 - acc: 0.9733\n",
      "Epoch 9: val_acc did not improve from 0.98611\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0765 - acc: 0.9733 - val_loss: 0.0516 - val_acc: 0.9826 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9820\n",
      "Epoch 10: val_acc did not improve from 0.98611\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0557 - acc: 0.9822 - val_loss: 0.0344 - val_acc: 0.9826 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9808\n",
      "Epoch 11: val_acc did not improve from 0.98611\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0617 - acc: 0.9811 - val_loss: 0.0702 - val_acc: 0.9826 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9796\n",
      "Epoch 12: val_acc did not improve from 0.98611\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0620 - acc: 0.9795 - val_loss: 0.0313 - val_acc: 0.9826 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0561 - acc: 0.9830\n",
      "Epoch 13: val_acc improved from 0.98611 to 0.99653, saving model to models/2023_05_28_19_09_10.h5\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0561 - acc: 0.9830 - val_loss: 0.0144 - val_acc: 0.9965 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9836\n",
      "Epoch 14: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0537 - acc: 0.9838 - val_loss: 0.0264 - val_acc: 0.9896 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0559 - acc: 0.9783\n",
      "Epoch 15: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0559 - acc: 0.9783 - val_loss: 0.0332 - val_acc: 0.9896 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0381 - acc: 0.9880\n",
      "Epoch 16: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0381 - acc: 0.9880 - val_loss: 0.0335 - val_acc: 0.9896 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9890\n",
      "Epoch 17: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0424 - acc: 0.9892 - val_loss: 0.0510 - val_acc: 0.9896 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0335 - acc: 0.9896\n",
      "Epoch 18: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0335 - acc: 0.9896 - val_loss: 0.0463 - val_acc: 0.9931 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9839\n",
      "Epoch 19: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0476 - acc: 0.9838 - val_loss: 0.0142 - val_acc: 0.9965 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9894\n",
      "Epoch 20: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0297 - acc: 0.9896 - val_loss: 0.0279 - val_acc: 0.9965 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9889\n",
      "Epoch 21: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0268 - acc: 0.9892 - val_loss: 0.0157 - val_acc: 0.9965 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9937\n",
      "Epoch 22: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0232 - acc: 0.9938 - val_loss: 0.0326 - val_acc: 0.9965 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0342 - acc: 0.9888\n",
      "Epoch 23: val_acc did not improve from 0.99653\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0342 - acc: 0.9888 - val_loss: 0.0102 - val_acc: 0.9931 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0245 - acc: 0.9919\n",
      "Epoch 24: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0245 - acc: 0.9919 - val_loss: 0.0182 - val_acc: 0.9965 - lr: 2.0000e-04\n",
      "Epoch 25/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0196 - acc: 0.9938\n",
      "Epoch 25: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0196 - acc: 0.9938 - val_loss: 0.0155 - val_acc: 0.9965 - lr: 2.0000e-04\n",
      "Epoch 26/50\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9933\n",
      "Epoch 26: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0158 - acc: 0.9930 - val_loss: 0.0269 - val_acc: 0.9931 - lr: 2.0000e-04\n",
      "Epoch 27/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9953\n",
      "Epoch 27: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0205 - acc: 0.9950 - val_loss: 0.0236 - val_acc: 0.9965 - lr: 2.0000e-04\n",
      "Epoch 28/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9922\n",
      "Epoch 28: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0265 - acc: 0.9923 - val_loss: 0.0262 - val_acc: 0.9965 - lr: 2.0000e-04\n",
      "Epoch 29/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9973\n",
      "Epoch 29: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0149 - acc: 0.9973 - val_loss: 0.0196 - val_acc: 0.9965 - lr: 2.0000e-04\n",
      "Epoch 30/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0156 - acc: 0.9957\n",
      "Epoch 30: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0156 - acc: 0.9957 - val_loss: 0.0148 - val_acc: 0.9965 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9957\n",
      "Epoch 31: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0137 - acc: 0.9957 - val_loss: 0.0264 - val_acc: 0.9931 - lr: 2.0000e-04\n",
      "Epoch 32/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0131 - acc: 0.9957\n",
      "Epoch 32: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0131 - acc: 0.9957 - val_loss: 0.0218 - val_acc: 0.9931 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0150 - acc: 0.9961\n",
      "Epoch 33: val_acc did not improve from 0.99653\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0150 - acc: 0.9961 - val_loss: 0.0210 - val_acc: 0.9965 - lr: 2.0000e-04\n",
      "Epoch 34/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0137 - acc: 0.9957\n",
      "Epoch 34: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0137 - acc: 0.9957 - val_loss: 0.0246 - val_acc: 0.9965 - lr: 4.0000e-05\n",
      "Epoch 35/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0125 - acc: 0.9961\n",
      "Epoch 35: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0125 - acc: 0.9961 - val_loss: 0.0256 - val_acc: 0.9931 - lr: 4.0000e-05\n",
      "Epoch 36/50\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9972\n",
      "Epoch 36: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0100 - acc: 0.9973 - val_loss: 0.0248 - val_acc: 0.9965 - lr: 4.0000e-05\n",
      "Epoch 37/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9957\n",
      "Epoch 37: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0122 - acc: 0.9957 - val_loss: 0.0225 - val_acc: 0.9965 - lr: 4.0000e-05\n",
      "Epoch 38/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0111 - acc: 0.9973\n",
      "Epoch 38: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0111 - acc: 0.9973 - val_loss: 0.0200 - val_acc: 0.9965 - lr: 4.0000e-05\n",
      "Epoch 39/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9973\n",
      "Epoch 39: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0105 - acc: 0.9973 - val_loss: 0.0238 - val_acc: 0.9965 - lr: 4.0000e-05\n",
      "Epoch 40/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9965\n",
      "Epoch 40: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0169 - acc: 0.9965 - val_loss: 0.0249 - val_acc: 0.9965 - lr: 4.0000e-05\n",
      "Epoch 41/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9961\n",
      "Epoch 41: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0115 - acc: 0.9961 - val_loss: 0.0286 - val_acc: 0.9931 - lr: 4.0000e-05\n",
      "Epoch 42/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0138 - acc: 0.9961\n",
      "Epoch 42: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0138 - acc: 0.9961 - val_loss: 0.0312 - val_acc: 0.9931 - lr: 4.0000e-05\n",
      "Epoch 43/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9977\n",
      "Epoch 43: val_acc did not improve from 0.99653\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0086 - acc: 0.9977 - val_loss: 0.0297 - val_acc: 0.9965 - lr: 4.0000e-05\n",
      "Epoch 44/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0124 - acc: 0.9969\n",
      "Epoch 44: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0124 - acc: 0.9969 - val_loss: 0.0298 - val_acc: 0.9965 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9976\n",
      "Epoch 45: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0082 - acc: 0.9977 - val_loss: 0.0286 - val_acc: 0.9965 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0149 - acc: 0.9977\n",
      "Epoch 46: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0149 - acc: 0.9977 - val_loss: 0.0284 - val_acc: 0.9965 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0117 - acc: 0.9977\n",
      "Epoch 47: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0117 - acc: 0.9977 - val_loss: 0.0287 - val_acc: 0.9965 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0137 - acc: 0.9957\n",
      "Epoch 48: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0137 - acc: 0.9957 - val_loss: 0.0283 - val_acc: 0.9965 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9965\n",
      "Epoch 49: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0176 - acc: 0.9965 - val_loss: 0.0271 - val_acc: 0.9965 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0145 - acc: 0.9957\n",
      "Epoch 50: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.0145 - acc: 0.9957 - val_loss: 0.0277 - val_acc: 0.9965 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10faf7690>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "\n",
    "model.fit_generator(\n",
    "\ttrain_generator, epochs=50, validation_data=val_generator,\n",
    " callbacks=[\n",
    "\t ModelCheckpoint('models/%s.h5'%(start_time), monitor='val_acc', save_best_only=True, mode='max', verbose=1),\n",
    "  ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n",
    " ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step\n",
      "test add : 0.9965277777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 19:10:18.774470: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "model = load_model('models/%s.h5'% (start_time))\n",
    "\n",
    "y_pred = model.predict(x_val/255.)\n",
    "y_pred_logical = (y_pred > 0.5).astype(np.int0)\n",
    "\n",
    "print(\"test add : %s\"%accuracy_score(y_val, y_pred_logical))\n",
    "cm = confusion_matrix(y_val, y_pred_logical)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 카메라 모듈 화면 표시 & 얼굴인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "model = load_model('models/2023_05_28_18_08_53.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "    x1, y1 = np.amin(eye_points, axis=0)\n",
    "    x2, y2 = np.amin(eye_points, axis=0)\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "    \n",
    "    w = (x2 -x1) * 1.2\n",
    "    h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "    \n",
    "    margin_x, margin_y = w / 2, h / 2\n",
    "    \n",
    "    min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "    max_x, max_y = int(cx - margin_x), int(cy + margin_y)\n",
    "    \n",
    "    eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int0)\n",
    "    eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "    \n",
    "    return (eye_img, eye_rect)\n",
    "\n",
    "cap = cv2.VideoCapture('http://192.168.0.109:81/stream')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img_ori = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"video road fail\")\n",
    "        break\n",
    "    \n",
    "    img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "    \n",
    "    img = img_ori.copy()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = detector(gray)\n",
    "    \n",
    "    for face in faces:\n",
    "        shapes = predictor(gray, face)\n",
    "        shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "        eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "        eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "        eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "        eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "        eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "        cv2.imshow('l', eye_img_l)\n",
    "        cv2.imshow('r', eye_img_r)\n",
    "\n",
    "        eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "        eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "        pred_l = model.predict(eye_input_l)\n",
    "        pred_r = model.predict(eye_input_r)\n",
    "\n",
    "        # visualize\n",
    "        state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "        state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "        state_l = state_l % pred_l\n",
    "        state_r = state_r % pred_r\n",
    "\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "        cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "        cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "    cv2.imshow('result', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "from imutils import face_utils\n",
    "import dlib\n",
    "import cv2\n",
    "import easydict\n",
    "from math import hypot\n",
    "\n",
    "args = easydict.EasyDict({\"shape_predictor\": \"./shape_predictor_68_face_landmarks.dat\"})\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(args[\"shape_predictor\"])\n",
    "\n",
    "video = cv2.VideoCapture('http://192.168.0.109:81/stream')\t#카메라모듈 스트리밍 주소\n",
    "frame_size = (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "r_eye_points = [42, 43, 44, 45, 46, 47]\n",
    "l_eye_points = [36, 37, 38, 39, 40, 41]\n",
    "\n",
    "def midpoint(p1, p2):\n",
    "    return int((p1.x + p2.x) / 2), int((p1.y + p2.y) / 2)\n",
    "\n",
    "def get_blinking_ratio(eye_points, facial_landmarks):\n",
    "    left_point = (facial_landmarks.part(eye_points[0]).x, facial_landmarks.part(eye_points[0].y))\n",
    "    right_point = (facial_landmarks.part(eye_points[3]).x, facial_landmarks.part(eye_points[3].y))\n",
    "    center_top = midpoint(facial_landmarks.part(eye_points[1]), facial_landmarks.part(eye_points[2]))\n",
    "    center_bottom = midpoint(facial_landmarks.part(eye_points[5]), facial_landmarks.part(eye_points[4]))\n",
    "\n",
    "    hor_line = cv2.line(frame, left_point, right_point, (0, 255, 0), 2)\n",
    "    ver_line = cv2.line(frame, center_top,center_bottom, (0, 255, 0), 2)\n",
    "\n",
    "    hor_line_length = hypot((left_point[0] - right_point[0]), (left_point[1] -right_point[1]))\n",
    "    ver_line_length = hypot((center_top[0] - center_bottom[0]), (center_top[1] - center_bottom[1]))\n",
    "    ratio = hor_line_length / ver_line_length\n",
    "    return (ratio)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"video road fail\")\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    if (len(rects) > 0):\n",
    "        text = \"{} face(s) found\".format(len(rects))\n",
    "        cv2.putText(frame, text, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        \n",
    "    for rect in rects:\n",
    "        (bX, bY, bW, bH) = face_utils.rect_to_bb(rect)\n",
    "        cv2.rectangle(frame, (bX, bY), (bX + bW, bY + bH), (0, 255, 0), 1)\n",
    "        \n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        \n",
    "        # for (i, (x, y)) in enumerate(shape):\n",
    "        #     cv2.circle(frame, (x, y), 1, (0, 0, 255), -1)\n",
    "        #     cv2.putText(frame, str(i + 1), (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    "\n",
    "        #눈 깜빡인 체크\n",
    "        # left_eye_ratio = get_blinking_ratio(l_eye_points, shape)\n",
    "        # right_eye_ratio = get_blinking_ratio(r_eye_points, shape)\n",
    "        # blinking_ratio = (left_eye_ratio + right_eye_ratio) / 2\n",
    "        # if (blinking_ratio >= 0.6):     ## ratio가 높으면 눈 감음\n",
    "        #     cv2.putText(frame, \"blinking\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0))\n",
    "        #     print(\"blinking\")\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if (key == ord(\"q\")):\n",
    "        break\n",
    "    \n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "# import dlib\n",
    "import cv2\n",
    "import easydict\n",
    "from math import hypot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
